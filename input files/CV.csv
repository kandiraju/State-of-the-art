Area,Parent Task,Task,Dataset,Best method name,Primary metric,Primary metric - is higher better ?,Earliest reported value,Latest reported value,Earliest reported value scaled,earliest  Percentile ( low/ high),Latest reported value scaled,Latest Percentile  ( low/ high),Bucket
Computer Vision,Semantic Segmentation,Semantic Segmentation,PASCAL VOC 2012,DeepLabv3+ (Xception-JFT),Mean IoU,TRUE,0.7,0.89,0.69,Low,0.35,low,1
Computer Vision,Semantic Segmentation,Semantic Segmentation,Cityscapes,DeepLabv3+ (Xception-JFT),Mean IoU,TRUE,0.63,0.82,0.62,Low,0.32,low,1
Computer Vision,Semantic Segmentation,Semantic Segmentation,PASCAL Context,Joint Pyramid Upsampling + EncNet,mIoU,TRUE,37.8,53.1,38.06,High,24.1,High,4
Computer Vision,Semantic Segmentation,Semantic Segmentation,ADE20K,PSPNet,Validation mIoU,TRUE,29.39,44.94,29.59,High,20.39,High,4
Computer Vision,Semantic Segmentation,Semantic Segmentation,CamVid,PSPNet,Mean IoU,TRUE,0.62,0.69,0.61,Low,0.26,low,1
Computer Vision,Semantic Segmentation,Semantic Segmentation,ShapeNet,SGPN,Mean IoU,TRUE,0.85,0.86,0.85,Low,0.34,low,1
Computer Vision,Semantic Segmentation,Semantic Segmentation,NYU Depth v2,Dilated FCN-2s RGB,Mean IoU,TRUE,0.32,0.32,0.31,Low,0.1,low,1
Computer Vision,Image Classification,Image Classification,CIFAR-10,GPIPE + transfer learning,Percentage correct,TRUE,88.8,99,89.42,High,44.97,High,4
Computer Vision,Image Classification,Image Classification,CIFAR-100,GPIPE,Percentage correct,TRUE,57.5,91.3,57.9,High,41.47,High,4
Computer Vision,Image Classification,Image Classification,ImageNet,GPIPE,Top 1 Accuracy,TRUE,0.7,0.84,0.69,Low,0.33,low,1
Computer Vision,Image Classification,Image Classification,STL-10,IIC,Percentage correct,TRUE,70.1,88.8,70.59,High,40.33,High,4
Computer Vision,Image Classification,Image Classification,MSRC-21 (per-class),Large FC CRF,Percentage correct,TRUE,,,,Low,,low,1
Computer Vision,Image Classification,Image Classification,MSRC-21 (per-pixel),HCRF+CO,Percentage correct,TRUE,,,,Low,,low,1
Computer Vision,Image Classification,Image Classification,iNaturalist,IncResNetV2 SE,Top 1 Accuracy,TRUE,0.67,0.67,0.66,Low,0.25,low,1
Computer Vision,Object Detection,Object Detection,COCO,SNIPER,Bounding Box AP,TRUE,34.9,47.6,35.14,High,21.6,High,4
Computer Vision,Object Detection,Object Detection,PASCAL VOC 2007,SNIPER,MAP,TRUE,0.82,0.87,0.82,Low,0.35,low,1
Computer Vision,Object Detection,Object Detection,ImageNet Detection,Inception V1,MAP,TRUE,0.24,0.44,0.23,Low,0.15,low,1
Computer Vision,Image Generation,Image Generation,CIFAR-10,PGGAN,Inception score,TRUE,5.34,8.8,5.37,Low,3.95,low,1
Computer Vision,Pose Estimation,Pose Estimation,MPII Human Pose,HRNet-32,PCKh-0.5,TRUE,0.82,0.92,0.82,Low,0.37,low,1
Computer Vision,Pose Estimation,Pose Estimation,Leeds Sports Poses,Pyramid Residual Modules (PRMs),PCK,TRUE,0.91,0.94,0.91,Low,0.38,low,1
Computer Vision,Pose Estimation,Pose Estimation,FLIC Elbows,Stacked Hourglass Networks,PCK@0.2,TRUE,0.98,0.99,0.98,Low,0.4,low,1
Computer Vision,Pose Estimation,Pose Estimation,FLIC Wrists,Stacked Hourglass Networks,PCK@0.2,TRUE,0.95,0.97,0.95,Low,0.39,low,1
Computer Vision,Pose Estimation,Pose Estimation,DensePose-COCO,Parsing R-CNN + ResNext101,AP,TRUE,55.8,61.6,56.19,High,27.96,High,4
Computer Vision,Pose Estimation,Pose Estimation,ITOP top-view,V2V-PoseNet,Mean mAP,TRUE,75.5,83.44,76.03,High,37.9,High,4
Computer Vision,Pose Estimation,Pose Estimation,COCO,HRNet-48,Mean mAP,TRUE,73.7,77,74.22,High,34.97,High,4
Computer Vision,Pose Estimation,Pose Estimation, ITOP front-view,V2V-PoseNet,Mean mAP,TRUE,77.4,88.74,77.94,High,40.31,High,4
Computer Vision,Super Resolution,Super Resolution,Set5-2x,FALSR-A ,PSNR,TRUE,37.82,37.82,38.08,High,17.15,High,4
Computer Vision,Image Retrieval,Image Retrieval,Par106k,DELF+FT+ATT+DIR+QE,Accuracy,TRUE,0.91,0.93,0.91,Low,0.37,low,1
Computer Vision,Image Retrieval,Image Retrieval,Oxf105k,DELF+FT+ATT+DIR+QE,MAP,TRUE,0.88,0.89,0.88,Low,0.35,low,1
Computer Vision,Image Retrieval,Image Retrieval,Par6k,DELF+FT+ATT+DIR+QE,Accuracy,TRUE,0.94,0.96,0.94,Low,0.39,low,1
Computer Vision,Image Retrieval,Image Retrieval,Oxf5k,DELF+FT+ATT+DIR+QE,MAP,TRUE,0.89,0.9,0.89,Low,0.36,low,1
Computer Vision,Image Retrieval,Image Retrieval,street2shop - topwear,Ranknet,Accuracy,TRUE,94.98,94.98,95.65,High,43.14,High,4
Computer Vision,Image Retrieval,Image Retrieval,INRIA Holidays,MultiGrain R50 @ 800,Mean mAP,TRUE,0.93,0.93,0.93,Low,0.37,low,1
Computer Vision,Image Retrieval,Image Retrieval,Stanford Cars,ABE-8-512,Recall@8,TRUE,96.1,96.1,96.78,High,43.65,High,4
Computer Vision,Action Recognition,Action Recognition,UCF101,Two-Stream I3D,Accuracy,TRUE,93.4,93.4,94.06,High,42.43,High,4
Computer Vision,Action Recognition,Action Recognition,HMDB51,Two-Stream I3D,Accuracy,TRUE,80.9,80.9,81.47,High,36.74,High,4
Computer Vision,Visual Question Answering,Visual Question Answering,COCO Visual Question Answering (VQA) real images 1.0 open ended,MCB 7 att.,Percentage correct,TRUE,58.2,66.5,58.61,High,30.19,High,4
Computer Vision,Visual Question Answering,Visual Question Answering,VQA v2,"Image features from bottom-up attention, adaptive K, ensemble",Accuracy,TRUE,0.62,0.7,0.61,Low,0.27,low,1
Computer Vision,Visual Question Answering,Visual Question Answering,COCO Visual Question Answering (VQA) real images 1.0 multiple choice,MCB 7 att.,Percentage correct,TRUE,63.1,70.1,63.54,High,31.83,High,4
Computer Vision,Visual Question Answering,Visual Question Answering,COCO Visual Question Answering (VQA) real images 2.0 open ended,Up-Down,Percentage correct,TRUE,68.16,70.34,68.64,High,31.94,High,4
Computer Vision,Visual Question Answering,Visual Question Answering,COCO Visual Question Answering (VQA) abstract 1.0 multiple choice,Graph VQA,Percentage correct,TRUE,71.18,74.37,71.68,High,33.77,High,4
Computer Vision,Visual Question Answering,Visual Question Answering,COCO Visual Question Answering (VQA) abstract images 1.0 open ended,Graph VQA,Percentage correct,TRUE,69.73,70.42,70.22,High,31.98,High,4
Computer Vision,Visual Question Answering,Visual Question Answering,Visual7W,CMN,Percentage correct,TRUE,62.2,72.53,62.63,High,32.93,High,4
Computer Vision,Visual Question Answering,Visual Question Answering,Visual Genome (subjects),CMN,Percentage correct,TRUE,44.24,44.24,44.55,High,20.07,High,4
Computer Vision,Visual Question Answering,Visual Question Answering,Visual Genome (pairs),CMN,Percentage correct,TRUE,28.52,28.52,28.71,High,12.92,High,4
Computer Vision,Super Resolution,Image Super-Resolution,Set5 - 4x upscaling,PFF,PSNR,TRUE,30.49,32.74,30.7,High,14.84,High,4
Computer Vision,Super Resolution,Image Super-Resolution,Set14 - 4x upscaling,SRGAN + Residual-in-Residual Dense Block,PSNR,TRUE,27.5,28.99,27.69,High,13.13,High,4
Computer Vision,Super Resolution,Image Super-Resolution,BSD100 - 4x upscaling,SRGAN + Residual-in-Residual Dense Block,PSNR,TRUE,26.9,27.85,27.08,High,12.62,High,4
Computer Vision,Super Resolution,Image Super-Resolution,Urban100 - 4x upscaling,SRGAN + Residual-in-Residual Dense Block,PSNR,TRUE,24.52,27.03,24.69,High,12.24,High,4
Computer Vision,Super Resolution,Image Super-Resolution,Manga109 - 4x upscaling,SRGAN + Residual-in-Residual Dense Block,SSIM,TRUE,0.86,0.92,0.86,Low,0.37,low,1
Computer Vision,Person Re-Identification,Person Re-Identification,Market-1501,Parameter-Free Spatial Attention,MAP,TRUE,22.22,91.7,22.37,High,41.65,High,4
Computer Vision,Person Re-Identification,Person Re-Identification,DukeMTMC-reID,Parameter-Free Spatial Attention,MAP,TRUE,17.04,85.9,17.15,High,39.01,High,4
Computer Vision,Instance Segmentation,Instance Segmentation,COCO,PANet,Average Precision,TRUE,0.25,0.42,0.24,Low,0.14,low,1
Computer Vision,Instance Segmentation,Instance Segmentation,NYU Depth v2,SGPN-CNN,MAP,TRUE,43.5,43.5,43.8,High,19.73,High,4
Computer Vision,Facial Recognition and Modelling,Face Recognition,Olivetti Faces 5 Image,RMDL,Accuracy,TRUE,95,95,95.67,High,43.15,High,4
Computer Vision,Facial Recognition and Modelling,Face Recognition,IJB-A,SE-GV-3,TAR @ FAR=0.01,TRUE,0.97,0.97,0.97,Low,0.39,low,1
Computer Vision,Facial Recognition and Modelling,Face Recognition,IJB-B,"GhostVLAD, SE-GV-3",TAR @ FAR=0.01,TRUE,0.96,0.96,0.96,Low,0.39,low,1
Computer Vision,Image Generation,Image-to-Image Translation,Cityscapes Labels-to-Photo,pix2pix,Class IOU,TRUE,0.02,0.18,0.01,Low,0.03,low,1
Computer Vision,Image Generation,Image-to-Image Translation,Cityscapes Photo-to-Labels,pix2pix,Class IOU,TRUE,0.07,0.32,0.06,Low,0.1,low,1
Computer Vision,Image Generation,Image-to-Image Translation,ADE20K-Outdoor Labels-to-Photos,SPADE,mIoU,TRUE,16.5,30.8,16.61,High,13.96,High,4
Computer Vision,Image Generation,Image-to-Image Translation,COCO-Stuff Labels-to-Photos,SPADE,mIoU,TRUE,23.7,37.4,23.86,High,16.96,High,4
Computer Vision,Image Generation,Image-to-Image Translation,ADE20K Labels-to-Photos,SPADE,mIoU,TRUE,22.4,38.5,22.55,High,17.46,High,4
Computer Vision,Image Generation,Image-to-Image Translation,Aerial-to-Map,cGAN,Class IOU,TRUE,0.26,0.26,0.25,Low,0.07,low,1
Computer Vision,Image Generation,Image-to-Image Translation,SYNTHIA-to-Cityscapes,superpixel + color constancy,mIoU,TRUE,20.2,29.7,20.33,High,13.46,High,4
Computer Vision,Image Generation,Image-to-Image Translation,SYNTHIA Fall-to-Winter,CyCADA,mIoU,TRUE,59.6,63.3,60.02,High,28.74,High,4
Computer Vision,Denoising,Image Denoising,BSD68 sigma50,MWCNN,PSNR,TRUE,26.23,26.53,26.41,High,12.02,High,4
Computer Vision,Denoising,Image Denoising,BSD68 sigma25,NLRN,PSNR,TRUE,29.23,29.41,29.43,High,13.32,High,4
Computer Vision,Denoising,Image Denoising,Urban100 sigma50,Residual Dense Network +,PSNR,TRUE,26.32,29.38,26.5,High,13.31,High,4
Computer Vision,Denoising,Image Denoising,BSD68 sigma15,NLRN,PSNR,TRUE,31.73,31.88,31.95,High,14.45,High,4
Computer Vision,Denoising,Image Denoising,Urban100 sigma70,Residual Dense Network +,PSNR,TRUE,24.63,27.74,24.8,High,12.57,High,4
Computer Vision,Denoising,Image Denoising,BSD68 sigma70,Residual Dense Network +,PSNR,TRUE,26.56,26.88,26.74,High,12.17,High,4
Computer Vision,Denoising,Image Denoising,BSD68 sigma30,Residual Dense Network +,PSNR,TRUE,30.4,30.7,30.61,High,13.91,High,4
Computer Vision,Denoising,Image Denoising,Urban100 sigma30,Residual Dense Network +,PSNR,TRUE,30.19,31.78,30.4,High,14.4,High,4
Computer Vision,Denoising,Image Denoising,BSD68 sigma10,Residual Dense Network +,PSNR,TRUE,36.31,36.49,36.56,High,16.54,High,4
Computer Vision,Denoising,Image Denoising,BSD200 sigma50,RED30,PSNR,TRUE,25.75,25.75,25.92,High,11.66,High,4
Computer Vision,Denoising,Image Denoising,BSD200 sigma30,RED30,PSNR,TRUE,27.95,27.95,28.14,High,12.66,High,4
Computer Vision,Denoising,Image Denoising,BSD200 sigma70,RED30,PSNR,TRUE,24.37,24.37,24.53,High,11.03,High,4
Computer Vision,Denoising,Image Denoising,BSD200 sigma10,RED30,PSNR,TRUE,33.63,33.63,33.86,High,15.24,High,4
Computer Vision,Facial Recognition and Modelling,Face Detection,WIDER Face (Hard),DSFD,AP,TRUE,0.29,0.9,0.28,Low,0.36,low,1
Computer Vision,Facial Recognition and Modelling,Face Detection,WIDER Face (Easy),DSFD,AP,TRUE,0.7,0.96,0.69,Low,0.39,low,1
Computer Vision,Facial Recognition and Modelling,Face Detection,WIDER Face (Medium),DSFD,AP,TRUE,0.59,0.95,0.58,Low,0.38,low,1
Computer Vision,Facial Recognition and Modelling,Face Detection,Annotated Faces in the Wild,SRN,AP,TRUE,0.97,1,0.97,Low,0.4,low,1
Computer Vision,Facial Recognition and Modelling,Face Detection,FDDB,DSFD,AP,TRUE,0.86,0.99,0.86,Low,0.4,low,1
Computer Vision,Facial Recognition and Modelling,Face Detection,PASCAL Face,SRN,AP,TRUE,0.9,0.99,0.9,Low,0.4,low,1
Computer Vision,Object Localization,Object Localization,KITTI Cyclists Easy,Frustum PointNets,AP,TRUE,0.67,0.75,0.66,Low,0.29,low,1
Computer Vision,Object Localization,Object Localization,KITTI Pedestrians Easy,Frustum PointNets,AP,TRUE,0.46,0.58,0.45,Low,0.21,low,1
Computer Vision,Object Localization,Object Localization,KITTI Cars Moderate,Frustum PointNets,AP,TRUE,0.79,0.84,0.79,Low,0.33,low,1
Computer Vision,Object Localization,Object Localization,KITTI Cyclists Hard,Frustum PointNets,AP,TRUE,0.51,0.55,0.5,Low,0.2,low,1
Computer Vision,Object Localization,Object Localization,KITTI Cyclists Moderate,Frustum PointNets,AP,TRUE,0.55,0.62,0.54,Low,0.23,low,1
Computer Vision,Object Localization,Object Localization,KITTI Cars Hard,VoxelNet,AP,TRUE,0.77,0.77,0.77,Low,0.3,low,1
Computer Vision,Object Localization,Object Localization,KITTI Cars Easy,VoxelNet,AP,TRUE,0.89,0.89,0.89,Low,0.35,low,1
Computer Vision,Object Localization,Object Localization,KITTI Pedestrians Hard,Frustum PointNets,AP,TRUE,0.38,0.47,0.37,Low,0.16,low,1
Computer Vision,Object Localization,Object Localization,KITTI Pedestrians Moderate,Frustum PointNets,AP,TRUE,0.41,0.5,0.4,Low,0.18,low,1
Computer Vision,3D,3D Reconstruction,Scan2CAD,Scan2CAD,Average Accuracy,TRUE,0.1,0.32,0.09,Low,0.1,low,1
Computer Vision,Facial Recognition and Modelling,Face Verification,Labeled Faces in the Wild,"ArcFace + MS1MV2 + R100, ",Accuracy,TRUE,0.99,1,0.99,Low,0.4,low,1
Computer Vision,Facial Recognition and Modelling,Face Verification,IJB-A,Dual-Agent GANs,TAR @ FAR=0.01,TRUE,0.73,0.98,0.73,Low,0.4,low,1
Computer Vision,Facial Recognition and Modelling,Face Verification,YouTube Faces DB,"SeqFace, 1 ResNet-64",Accuracy,TRUE,0.93,98.12,0.93,Low,44.57,High,2
Computer Vision,Facial Recognition and Modelling,Face Verification,MegaFace,ArcFace + MS1MV2 + R100 + R,Accuracy,TRUE,0.86,0.98,0.86,Low,0.4,low,1
Computer Vision,Facial Recognition and Modelling,Face Verification,IJB-C,AIM,TAR @ FAR=0.01,TRUE,0.67,0.94,0.66,Low,0.38,low,1
Computer Vision,Facial Recognition and Modelling,Face Verification,IJB-B,FPN,TAR @ FAR=0.01,TRUE,0.97,0.97,0.97,Low,0.39,low,1
Computer Vision,Image Generation,Conditional Image Generation,CIFAR-10,Splitting GAN,Inception score,TRUE,6.58,8.87,6.62,Low,3.98,low,1
Computer Vision,Image Generation,Conditional Image Generation,ImageNet 128x128,BigGAN-deep,Inception score,TRUE,28.5,166.5,28.69,High,75.67,High,4
Computer Vision,Scene Text Detection,Scene Text Detection,IC15,FOTS,F-Measure,TRUE,0.76,0.88,0.76,Low,0.35,low,1
Computer Vision,Scene Text Detection,Scene Text Detection,IC17-MLT,PSENet-1s,F-Measure,TRUE,0.67,0.72,0.66,Low,0.28,low,1
Computer Vision,Object Detection,3D Object Detection,KITTI Cars Moderate,PointRCNN,AP,TRUE,0.65,0.75,0.64,Low,0.29,low,1
Computer Vision,Object Detection,3D Object Detection,KITTI Cars Hard,PointRCNN,AP,TRUE,0.58,0.68,0.57,Low,0.26,low,1
Computer Vision,Object Detection,3D Object Detection,KITTI Cars Easy,PC-CNN-V2,AP,TRUE,0.77,0.84,0.77,Low,0.33,low,1
Computer Vision,Object Detection,3D Object Detection,KITTI Pedestrians Moderate,Frustum PointNets,AP,TRUE,0.34,0.45,0.33,Low,0.15,low,1
Computer Vision,Object Detection,3D Object Detection,KITTI Cyclists Moderate,PointPillars,AP,TRUE,0.48,0.59,0.47,Low,0.22,low,1
Computer Vision,Object Detection,3D Object Detection,KITTI Cyclists Easy,Frustum PointNets,AP,TRUE,0.61,0.72,0.6,Low,0.28,low,1
Computer Vision,Object Detection,3D Object Detection,KITTI Pedestrians Hard,IPOD,AP,TRUE,0.32,0.42,0.31,Low,0.14,low,1
Computer Vision,Object Detection,3D Object Detection,KITTI Pedestrians Easy,IPOD,AP,TRUE,0.39,0.57,0.38,Low,0.21,low,1
Computer Vision,Object Detection,3D Object Detection,KITTI Cyclists Hard,Frustum PointNets,AP,TRUE,0.44,0.5,0.43,Low,0.18,low,1
Computer Vision,Object Detection,3D Object Detection,SUN-RGBD,Frustum PointNets,MAP,TRUE,0.54,0.54,0.53,Low,0.2,low,1
Computer Vision,Object Detection,3D Object Detection,NYU Depth v2,SGPN-CNN,MAP,TRUE,41.3,41.3,41.59,High,18.73,High,4
Computer Vision,Semantic Segmentation,Real-Time Semantic Segmentation,Cityscapes,PSPNet,mIoU,TRUE,0.63,0.81,0.62,Low,0.32,low,1
Computer Vision,Semantic Segmentation,Real-Time Semantic Segmentation,CamVid,PSPNet,mIoU,TRUE,0.62,0.69,0.61,Low,0.26,low,1
Computer Vision,Image-to-Image Translation,Unsupervised Image-To-Image Translation,SVNH-to-MNIST,CyCADA pixel+feat,Classification Accuracy,TRUE,0.74,0.9,0.74,Low,0.36,low,1
Computer Vision,Object Detection,Real-Time Object Detection,PASCAL VOC 2007,YOLO,FPS,TRUE,7,46,7.04,Low,20.87,High,2
Computer Vision,Object Detection,Real-Time Object Detection,COCO,YOLOv3-tiny,FPS,TRUE,40,220,40.28,High,100,High,4
Computer Vision,Facial Recognition and Modelling,Facial Expression Recognition, Static Facial Expressions in the Wild,Covariance Pooling,Accuracy,TRUE,0.58,0.58,0.57,Low,0.21,low,1
Computer Vision,Facial Recognition and Modelling,Facial Expression Recognition,Real-World Affective Faces,Covariance Pooling,Accuracy,TRUE,0.87,0.87,0.87,Low,0.35,low,1
Computer Vision,Facial Recognition and Modelling,Facial Expression Recognition,Cohn-Kanade,Sequential forward selection,Accuracy,TRUE,0.89,0.89,0.89,Low,0.35,low,1
Computer Vision,Facial Recognition and Modelling,Facial Expression Recognition,MMI,DeXpression,Accuracy,TRUE,0.99,0.99,0.99,Low,0.4,low,1
Computer Vision,Pose Estimation,Multi-Person Pose Estimation,MPII Multi-Person,Regional Multi-Person Pose Estimation,AP,TRUE,0.59,0.82,0.58,Low,0.32,low,1
Computer Vision,Pose Estimation,Multi-Person Pose Estimation,WAF,DeeperCut,AOP,TRUE,0.87,0.88,0.87,Low,0.35,low,1
Computer Vision,Pose Estimation,Multi-Person Pose Estimation,COCO,HRNet-48,AP,TRUE,0.7,0.77,0.69,Low,0.3,low,1
Computer Vision,Edge Detection,Edge Detection,SBD,CASENet,Maximum F-measure,TRUE,0.71,0.71,0.71,Low,0.27,low,1
Computer Vision,Edge Detection,Edge Detection,Cityscapes,CASENet,AP,TRUE,0.71,0.71,0.71,Low,0.27,low,1
Computer Vision,Video,Visual Object Tracking,VOT2017/18,SiamMask,Expected Average Overlap (EAO),TRUE,0.26,0.38,0.25,Low,0.12,low,1
Computer Vision,Pose Estimation,Keypoint Detection,COCO,HRNet-48,Validation AP,TRUE,60.5,76.3,60.92,High,34.65,High,4
Computer Vision,Pose Estimation,Keypoint Detection, Pascal3D+,ConvNet + deformable shape model,Mean PCK,TRUE,48.5,82.5,48.84,High,37.47,High,4
Computer Vision,Facial Recognition and Modelling,Face Identification,MegaFace,ArcFace + MS1MV2 + R100 + R,Accuracy,TRUE,0.7,0.98,0.69,Low,0.4,low,1
Computer Vision,Facial Recognition and Modelling,Face Identification,IJB-A,Deep Residual Equivariant Mapping,Accuracy,TRUE,0.91,0.95,0.91,Low,0.38,low,1
Computer Vision,Facial Recognition and Modelling,Face Identification,IJB-B,FPN,Accuracy,TRUE,0.91,0.91,0.91,Low,0.36,low,1
Computer Vision,Object Reconstruction,3D Object Reconstruction,Data3Dâ€šÃ Ã­R2N2,MVD,Avg F1,TRUE,39.01,66.39,39.28,High,30.14,High,4
Computer Vision,Image Classification,Few-Shot Image Classification,Mini-ImageNet - 5-Shot Learning,MetaOptNet-SVM,Accuracy,TRUE,0.55,0.79,0.54,Low,0.31,low,1
Computer Vision,Image Classification,Few-Shot Image Classification,Mini-ImageNet - 1-Shot Learning,MetaOptNet-SVM,Accuracy,TRUE,0.44,0.63,0.43,Low,0.24,low,1
Computer Vision,Image Classification,Few-Shot Image Classification,OMNIGLOT - 1-Shot Learning,Prototypical-Nets,Accuracy,TRUE,0.98,0.99,0.98,Low,0.4,low,1
Computer Vision,Image Classification,Few-Shot Image Classification,OMNIGLOT - 5-Shot Learning,MAML,Accuracy,TRUE,1,1,1,Low,0.4,low,1
Computer Vision,Image Classification,Few-Shot Image Classification,CUB-200 - 0-Shot Learning,Prototypical-Nets,Accuracy,TRUE,0.5,0.55,0.49,Low,0.2,low,1
Computer Vision,Video,Video Super-Resolution,Vid4 - 4x upscaling,VSR-DUF,PSNR,TRUE,24.68,27.31,24.85,High,12.37,High,4
Computer Vision,Video,Video Super-Resolution,Xiph HD - 4x upscaling,ESPCN,Average PSNR,TRUE,31.47,31.67,31.68,High,14.35,High,4
Computer Vision,Video,Video Super-Resolution,Ultra Video Group HD - 4x upscaling,ESPCN,Average PSNR,TRUE,37.52,37.91,37.78,High,17.19,High,4
Computer Vision,Video,Action Recognition In Videos,Charades,LFB NL,MAP,TRUE,24.1,42.5,24.26,High,19.28,High,4
Computer Vision,Object Detection,Weakly Supervised Object Detection,PASCAL VOC 2007,pipeline method,MAP,TRUE,39.3,51.2,39.57,High,23.23,High,4
Computer Vision,Object Detection,Weakly Supervised Object Detection,PASCAL VOC 2012,PCL-OB-G-Ens + FRCNN,MAP,TRUE,35.3,44.2,35.54,High,20.05,High,4
Computer Vision,Object Detection,Weakly Supervised Object Detection,ImageNet,PCL-OB-G-Ens + FRCNN,MAP,TRUE,16.3,19.6,16.41,High,8.86,low,3
Computer Vision,Object Detection,Weakly Supervised Object Detection,COCO,MSLPD,MAP,TRUE,43.5,56.6,43.8,High,25.69,High,4
Computer Vision,Semantic Segmentation,Scene Segmentation,SUN-RGBD,DeepLab-LargeFOV,Mean IoU,TRUE,32.08,32.08,32.3,High,14.54,High,4
Computer Vision,Semantic Segmentation,Scene Segmentation,ScanNet,3DMV,Average Accuracy,TRUE,0.6,0.75,0.59,Low,0.29,low,1
Computer Vision,Pose Estimation,6D Pose Estimation,LineMOD,PoseCNN + DeepIM,Accuracy,TRUE,0.84,0.98,0.84,Low,0.4,low,1
Computer Vision,Pose Estimation,6D Pose Estimation,OccludedLINEMOD,PoseCNN + ICP,Accuracy,TRUE,0.77,0.78,0.77,Low,0.3,low,1
Computer Vision,Pose Estimation,6D Pose Estimation,YCB-Video,DenseFusion,Mean AUC,TRUE,0.93,0.93,0.93,Low,0.37,low,1
Computer Vision,Pose Estimation,6D Pose Estimation,OCCLUSION,Single-shot deep CNN,MAP,TRUE,0.48,0.48,0.47,Low,0.17,low,1
Computer Vision,Pose Estimation,6D Pose Estimation,T-LESS,RetinaNet+Augmented Autoencoders+ICP,Accuracy,TRUE,57.14,57.14,57.54,High,25.94,High,4
Computer Vision,Image Classification,Semi-Supervised Image Classification,"CIFAR-10, 4000 Labels",SWSA,Accuracy,TRUE,79.6,95,80.16,High,43.15,High,4
Computer Vision,Image Classification,Semi-Supervised Image Classification,"SVHN, 1000 labels",VAT+EntMin,Accuracy,TRUE,91.89,96.14,92.54,High,43.67,High,4
Computer Vision,Image Classification,Semi-Supervised Image Classification,STL-10,IIC,Accuracy,TRUE,88.8,88.8,89.42,High,40.33,High,4
Computer Vision,Emotion Recognition,Multimodal Emotion Recognition,IEMOCAP,CHFusion,F1,TRUE,0.55,0.55,0.54,Low,0.2,low,1
Computer Vision,Emotion Recognition,Multimodal Emotion Recognition,Monologue,bc-LSTM,Accuracy,TRUE,0.74,0.74,0.74,Low,0.29,low,1
Computer Vision,Image-to-Image Translation,Synthetic-to-Real Translation,GTAV-to-Cityscapes Labels,Domain adaptation + ResNet-101,mIoU,TRUE,27.1,43.2,27.28,High,19.6,High,4
Computer Vision,Image Classification,Fine-Grained Image Classification, CUB-200-2011,Inception-V3,Accuracy,TRUE,0.76,89.6,0.76,Low,40.7,High,2
Computer Vision,Image Classification,Fine-Grained Image Classification,Stanford Cars,WS-DAN,Accuracy,TRUE,0.93,0.95,0.93,Low,0.38,low,1
Computer Vision,Image Classification,Fine-Grained Image Classification,FGVC Aircraft,WS-DAN,Accuracy,TRUE,0.91,0.93,0.91,Low,0.37,low,1
Computer Vision,Image Classification,Fine-Grained Image Classification,CompCars,A3M,Accuracy,TRUE,0.91,0.95,0.91,Low,0.38,low,1
Computer Vision,Image Classification,Fine-Grained Image Classification,Stanford Dogs,WS-DAN,Accuracy,TRUE,0.84,92.1,0.84,Low,41.83,High,2
Computer Vision,Image Classification,Fine-Grained Image Classification,Oxford 102 Flowers,PC Bilinear CNN,Accuracy,TRUE,0.94,0.94,0.94,Low,0.38,low,1
Computer Vision,Image Classification,Fine-Grained Image Classification,NABirds,PC-DenseNet-161,Accuracy,TRUE,0.83,0.83,0.83,Low,0.33,low,1
Computer Vision,Hyperspectral,Hyperspectral Image Classification,Indian Pines,BASSNet,Overall Accuracy,TRUE,0.97,0.97,0.97,Low,0.39,low,1
Computer Vision,Hyperspectral,Hyperspectral Image Classification,Pavia University,St-SS-pGRU,Overall Accuracy,TRUE,0.97,0.98,0.97,Low,0.4,low,1
Computer Vision,Autonomous Vehicles,Lane Detection,TuSimple,Spatial CNN,Accuracy,TRUE,0.96,0.97,0.96,Low,0.39,low,1
Computer Vision,Autonomous Vehicles,Lane Detection,Caltech Lanes Washington,VPGNet,F1,TRUE,0.86,0.87,0.86,Low,0.35,low,1
Computer Vision,Autonomous Vehicles,Lane Detection,Caltech Lanes Cordova,VPGNet,F1,TRUE,0.87,0.88,0.87,Low,0.35,low,1
Computer Vision,Image Generation,Text-to-Image Generation,COCO,AttnGAN,Inception score,TRUE,8.45,25.89,8.5,Low,11.72,High,2
Computer Vision,Image Generation,Text-to-Image Generation,CUB,AttnGAN,Inception score,TRUE,3.62,4.36,3.64,Low,1.93,low,1
Computer Vision,Image Generation,Text-to-Image Generation,MS-COCO,AttnGAN+OP,Inception score,TRUE,24.76,24.76,24.93,High,11.21,High,4
Computer Vision,Autonomous Vehicles,Traffic Sign Recognition,Tsinghua-Tencent 100K,Background Threshold Model,MAP,TRUE,0.32,0.32,0.31,Low,0.1,low,1
Computer Vision,Autonomous Vehicles,Traffic Sign Recognition,Bosch Small Traffic Lights,Hierarchical + Background Threshold Model,MAP,TRUE,0.46,0.46,0.45,Low,0.16,low,1
Computer Vision,Autonomous Vehicles,Traffic Sign Recognition,GTSRB,MCDNN,Accuracy,TRUE,1,1,1,Low,0.4,low,1
Computer Vision,Trajectory Prediction,Trajectory Prediction,GPS,Support Vector Machines,Accuracy,TRUE,0.88,0.88,0.88,Low,0.35,low,1
Computer Vision,Object Detection,Object Proposal Generation,"PASCAL VOC 2012, 60 proposals per image",Recurrent Pixel Embedding,Average Recall,TRUE,0.67,0.81,0.66,Low,0.32,low,1
Computer Vision,Object Recognition,3D Object Recognition,ModelNet40,MVCNN-MultiRes,Accuracy,TRUE,0.94,0.94,0.94,Low,0.38,low,1
Computer Vision,Human Part Segmentation,Human Part Segmentation,CIHP,Parsing R-CNN + ResNext101,Mean IoU,TRUE,55.8,61.1,56.19,High,27.74,High,4
Computer Vision,Human Part Segmentation,Human Part Segmentation,MHP v2.0,Parsing R-CNN + ResNext101,Mean IoU,TRUE,41.8,41.8,42.09,High,18.96,High,4
Computer Vision,Image Classification,Sequential Image Classification,Sequential MNIST,BN LSTM,Permuted Accuracy,TRUE,0.82,0.95,0.82,Low,0.38,low,1
Computer Vision,Human Parsing,Multi-Human Parsing,MHP v1.0,NAN,AP 0.5,TRUE,0.53,0.57,0.52,Low,0.21,low,1
Computer Vision,Human Parsing,Multi-Human Parsing,MHP v2.0,NAN,AP 0.5,TRUE,0.15,0.25,0.14,Low,0.06,low,1
Computer Vision,Human Parsing,Multi-Human Parsing,PASCAL-Person-Part,NAN,AP 0.5,TRUE,0.39,0.6,0.38,Low,0.22,low,1
Computer Vision,3D,3D Object Classification,ModelNet40,3D-PointCapsNet,Classification Accuracy,TRUE,0.89,0.89,0.89,Low,0.35,low,1
Computer Vision,Image-to-Image Translation,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Shoes,MUNIT,Diversity,TRUE,0.01,0.11,0,Low,0,low,1
Computer Vision,Image-to-Image Translation,Multimodal Unsupervised Image-To-Image Translation,Edge-to-Handbags,MUNIT,Diversity,TRUE,0.02,0.18,0.01,Low,0.03,low,1
Computer Vision,Image-to-Image Translation,Multimodal Unsupervised Image-To-Image Translation,Cats-and-Dogs,MUNIT,CIS,TRUE,0.12,1.04,0.11,Low,0.42,low,1
Computer Vision,Facial Recognition and Modelling,Age Estimation,MORPH Album2,CORAL,MAE,TRUE,2.42,2.59,2.43,Low,1.13,low,1
Computer Vision,Facial Recognition and Modelling,Age Estimation,AFAD,CORAL,MAE,TRUE,3.48,3.48,3.49,Low,1.53,low,1
Computer Vision,Facial Recognition and Modelling,Age Estimation,CACD,CORAL,MAE,TRUE,5.35,5.35,5.38,Low,2.38,low,1
Computer Vision,Facial Recognition and Modelling,Age Estimation,UTKFace,CORAL,MAE,TRUE,5.39,5.39,5.42,Low,2.4,low,1
Computer Vision,Object Detection,Medical Object Detection,Barrettâ€šÃ„Ã´s Esophagus,Attention-based model,Mean Accuracy,TRUE,0.74,0.81,0.74,Low,0.32,low,1
Computer Vision,Line segment detection,Line segment detection,wireframe dataset,atrous Residual U-Net,F1 score,TRUE,0.77,0.77,0.77,Low,0.3,low,1
Computer Vision,Scene Text Detection,Curved Text Detection,SCUT-CTW1500,PSENet-1s,F-Measure,TRUE,0.41,0.81,0.4,Low,0.32,low,1
Computer Vision,3D Reconstruction,3D Room Layouts From A Single Rgb Panorama,PanoContext,HorizonNet,3DIoU,TRUE,0.74,0.82,0.74,Low,0.32,low,1
Computer Vision,3D Reconstruction,3D Room Layouts From A Single Rgb Panorama,Stanford 2D-3D,HorizonNet,3DIoU,TRUE,0.76,0.8,0.76,Low,0.31,low,1
Computer Vision,3D Reconstruction,3D Room Layouts From A Single Rgb Panorama,Realtor360,DuLa-Net,3DIoU,TRUE,0.63,0.77,0.62,Low,0.3,low,1
Computer Vision,Facial Recognition and Modelling,Facial Inpainting,VggFace2,SymmFCNet (Full),PSNR,TRUE,27.81,27.81,28,High,12.6,High,4
Computer Vision,Facial Recognition and Modelling,Facial Inpainting,WebFace,SymmFCNet (Full),PSNR,TRUE,27.22,27.22,27.4,High,12.33,High,4
Computer Vision,Object Detection,Video Object Detection,ImageNet VID,FGFA + Seq-NMS,MAP,TRUE,0.8,0.8,0.8,Low,0.31,low,1
Computer Vision,Face Detection,Occluded Face Detection,MAFA,FAN,MAP,TRUE,0.77,0.88,0.77,Low,0.35,low,1
Computer Vision,Sketch,Face Sketch Synthesis,CUHK,Residual net + Pseudo Sketch Feature Loss + LSGAN,FSIM,TRUE,0.74,0.74,0.74,Low,0.29,low,1
Computer Vision,Sketch,Face Sketch Synthesis,CUFS,Residual net + Pseudo Sketch Feature Loss + LSGAN,FSIM,TRUE,0.73,0.73,0.73,Low,0.28,low,1
Computer Vision,Sketch,Face Sketch Synthesis,CUFSF,Residual net + Pseudo Sketch Feature Loss + LSGAN,FSIM,TRUE,0.72,0.72,0.72,Low,0.28,low,1
Computer Vision,Facial Recognition and Modelling,Facial Action Unit Detection,BP4D,Multi-View,Average Accuracy,TRUE,0.56,0.82,0.55,Low,0.32,low,1
Computer Vision,Facial Recognition and Modelling,Facial Beauty Prediction,ECCV HotOrNot,CNN features + Bayesian ridge regression,Pearson Correlation,TRUE,0.47,0.47,0.46,Low,0.16,low,1
Computer Vision,Facial Recognition and Modelling,Age-Invariant Face Recognition,CACDVS,AIM + CAFR,Accuracy,TRUE,0.98,1,0.98,Low,0.4,low,1
Computer Vision,Facial Recognition and Modelling,Age-Invariant Face Recognition,MORPH Album2,AIM + CAFR,Rank-1 Recognition Rate,TRUE,1,1,1,Low,0.4,low,1
Computer Vision,Facial Recognition and Modelling,Age-Invariant Face Recognition,CAFR,AIM,Accuracy,TRUE,0.74,0.85,0.74,Low,0.34,low,1
Computer Vision,Facial Recognition and Modelling,Age-Invariant Face Recognition,FG-NET,AIM,Accuracy,TRUE,0.93,0.93,0.93,Low,0.37,low,1
Computer Vision,Autonomous Vehicles,Pedestrian Attribute Recognition,PA-100K,HP-net,Accuracy,TRUE,0.72,0.72,0.72,Low,0.28,low,1
Computer Vision,Autonomous Vehicles,Pedestrian Attribute Recognition,PETA,HP-net,Accuracy,TRUE,0.76,0.76,0.76,Low,0.3,low,1
Computer Vision,Autonomous Vehicles,Pedestrian Attribute Recognition,RAP,HP-net,Accuracy,TRUE,0.65,0.65,0.64,Low,0.25,low,1
Computer Vision,Object Detection,Object Skeleton Detection,SK-LARGE,DeepFlux,F-Measure,TRUE,0.72,0.73,0.72,Low,0.28,low,1
Computer Vision,Face Verification,Disguised Face Verification,Disguised Faces in the Wild,DisguiseNet,GAR @0.1% FAR,TRUE,23.25,23.25,23.41,High,10.52,High,4
Computer Vision,Object Recognition,Depiction Invariant Object Recognition,Photo-Art-50,SwiDeN,Overall Accuracy,TRUE,0.93,0.93,0.93,Low,0.37,low,1
Computer Vision,Birds Eye View Object Detection,Birds Eye View Object Detection,KITTI Cars Moderate,PointPillars,AP,TRUE,0.86,0.86,0.86,Low,0.34,low,1
Computer Vision,Birds Eye View Object Detection,Birds Eye View Object Detection,KITTI Cyclists Moderate,PointPillars,AP,TRUE,0.62,0.62,0.61,Low,0.23,low,1
Computer Vision,Birds Eye View Object Detection,Birds Eye View Object Detection,KITTI Pedestrians Moderate,PointPillars,AP,TRUE,0.5,0.5,0.49,Low,0.18,low,1
Computer Vision,Safety Perception Recognition,Safety Perception Recognition,Google Street Images,CNN,Accuracy,TRUE,0.81,0.81,0.81,Low,0.32,low,1
Computer Vision,Image Classification,Unsupervised image classification,STL-10,IIC,Accuracy,TRUE,0.61,0.61,0.6,Low,0.23,low,1
Computer Vision,Image Classification,Unsupervised image classification,CIFAR-10,IIC,Accuracy,TRUE,61.7,61.7,62.13,High,28.01,High,4
Computer Vision,Image Classification,Unsupervised image classification,CIFAR-20,IIC,Accuracy,TRUE,25.7,25.7,25.87,High,11.64,High,4
Computer Vision,Image Classification,Unsupervised image classification,MNIST,IIC,Accuracy,TRUE,99.3,99.3,100,High,45.11,High,4
Computer Vision,Semantic Segmentation,Unsupervised semantic segmentation,COCO-Stuff-15,IIC,Accuracy,TRUE,27.7,27.7,27.89,High,12.55,High,4
Computer Vision,Semantic Segmentation,Unsupervised semantic segmentation,COCO-Stuff-3,IIC,Accuracy,TRUE,72.3,72.3,72.81,High,32.83,High,4
Computer Vision,Semantic Segmentation,Unsupervised semantic segmentation,Potsdam,IIC,Accuracy,TRUE,65.1,65.1,65.56,High,29.56,High,4
Computer Vision,Semantic Segmentation,Unsupervised semantic segmentation,Potsdam-3,IIC,Accuracy,TRUE,45.4,45.4,45.71,High,20.6,High,4
Computer Vision,Instance Segmentation,Human Instance Segmentation,OCHuman,Pose2Seg (plus ground-truth keypoints),AP,TRUE,0.55,0.55,0.54,Low,0.2,low,1
Computer Vision,Image Recognition,License Plate Recognition,Chinese License Plates,LPRNet basic,Accuracy,TRUE,0.95,0.95,0.95,Low,0.38,low,1
Computer Vision,Novel View Synthesis,Novel View Synthesis,KITTI Novel View Synthesis,Multi-view to Novel View,SSIM,TRUE,0.63,0.63,0.62,Low,0.24,low,1
Computer Vision,Novel View Synthesis,Novel View Synthesis,ShapeNet Car,Multi-view to Novel View,SSIM,TRUE,0.92,0.92,0.92,Low,0.37,low,1
Computer Vision,Novel View Synthesis,Novel View Synthesis,ShapeNet Chair,Multi-view to Novel View,SSIM,TRUE,0.9,0.9,0.9,Low,0.36,low,1
Computer Vision,Novel View Synthesis,Novel View Synthesis,Synthia Novel View Synthesis,Multi-view to Novel View,SSIM,TRUE,0.7,0.7,0.69,Low,0.27,low,1
Computer Vision,Object Detection,One-Shot Object Detection,COCO,Siamese Mask R-CNN,AP 0.5,TRUE,16.3,16.3,16.41,High,7.36,low,3
Computer Vision,3D,3D Part Segmentation,ShapeNet-Part,3D-PointCapsNet,Accuracy,TRUE,86,86,86.6,High,39.06,High,4
Computer Vision,Instance Segmentation,Real-time Instance Segmentation,MSCOCO,YOLACT,MAP,TRUE,29.8,29.8,30,High,13.5,High,4
Computer Vision,Facial Recognition and Modelling,Smile Recognition,DISFA,Deep CNN,Accuracy,TRUE,0.99,0.99,0.99,Low,0.4,low,1
Computer Vision,Image Classification,Document Image Classification,RVL-CDIP,Transfer Learning from VGG16 trained on Imagenet,Accuracy,TRUE,0.9,0.92,0.9,Low,0.37,low,1
Computer Vision,Image Classification,Image Classification,MNIST,RMDL,Percentage error,FALSE,0.2,0.18,0.04,Low,0.04,low,1
Computer Vision,Image Classification,Image Classification,SVHN,WRN + fixup init + mixup + cutout,Percentage error,FALSE,2.8,1.4,0.69,Low,0.34,low,1
Computer Vision,Image Classification,Image Classification,Fashion-MNIST,Random Erasing,Percentage error,FALSE,3.65,3.65,0.9,Low,0.9,low,1
Computer Vision,Image Classification,Image Classification,MultiMNIST,CapsNet,Percentage error,FALSE,5.2,5.2,1.28,Low,1.28,low,1
Computer Vision,Image Generation,Image Generation,LSUN Bedroom 256 x 256,COCO-GAN,FID,FALSE,9.5,6.95,2.35,Low,1.72,low,1
Computer Vision,Image Generation,Image Generation,CelebA-HQ 1024x1024,StyleGAN,FID,FALSE,7.3,5.06,1.8,Low,1.25,low,1
Computer Vision,Image Generation,Image Generation,CAT 256x256,RaSGAN,FID,FALSE,155.46,32.11,38.47,High,7.94,low,3
Computer Vision,Image Generation,Image Generation,FFHQ,StyleGAN,FID,FALSE,8.04,4.4,1.98,Low,1.08,low,1
Computer Vision,Optical Flow Estimation,Optical Flow Estimation,Sintel-clean,PWC-Net,Average End-Point Error,FALSE,6.64,3.45,1.64,Low,0.85,low,1
Computer Vision,Optical Flow Estimation,Optical Flow Estimation,Sintel-final,PWC-Net,Average End-Point Error,FALSE,8.36,4.6,2.06,Low,1.13,low,1
Computer Vision,Image Generation,Image-to-Image Translation,RaFD,StarGAN,Classification Error,FALSE,0.04,0.02,0,Low,0,low,1
Computer Vision,Image Reconstruction,Image Reconstruction,Edge-to-Shoes,PI-REC,FID,FALSE,0.02,0.02,0,Low,0,low,1
Computer Vision,Image Reconstruction,Image Reconstruction,Edge-to-Handbags,PI-REC,FID,FALSE,0.07,0.07,0.01,Low,0.01,low,1
Computer Vision,Pose Estimation,3D Human Pose Estimation,Human3.6M,Fully supervised EpipolarPose,Average 3D Error,FALSE,88.39,51.8,21.87,High,12.81,High,4
Computer Vision,Pose Estimation,3D Human Pose Estimation,CHALL H80K,ResNet,MPJPE,FALSE,55.3,55.3,13.68,Low,13.68,High,2
Computer Vision,Facial Recognition and Modelling,Face Alignment,AFLW2000-3D,2DASL,Mean NME ,FALSE,0.05,0.04,0.01,Low,0,low,1
Computer Vision,Facial Recognition and Modelling,Face Alignment,300W,DAN-Menpo + bounding box diagonal normalization,Mean Error Rate,FALSE,1.42,1.42,0.35,Low,0.35,low,1
Computer Vision,Facial Recognition and Modelling,Face Alignment,AFLW2000,Nonlinear 3D Face Morphable Model,Error rate,FALSE,4.7,4.7,1.16,Low,1.16,low,1
Computer Vision,Facial Recognition and Modelling,Face Alignment,AFLW-LFPA,FPN,Mean NME ,FALSE,0.04,0.03,0,Low,0,low,1
Computer Vision,Autonomous Vehicles,Pedestrian Detection,Caltech,CSP + CityPersons dataset,Reasonable Miss Rate,FALSE,20.9,3.8,5.17,Low,0.94,low,1
Computer Vision,Autonomous Vehicles,Pedestrian Detection,CityPersons,CSP (with offset) + ResNet-50,Reasonable MR^-2,FALSE,14.8,11,3.66,Low,2.72,low,1
Computer Vision,Video,Video Generation,TrailerFaces,PG-SWGAN-3D,FID,FALSE,404.1,404.1,100,High,100,High,4
Computer Vision,Hand,Hand Pose Estimation,NYU Hands,V2V-PoseNet,Average 3D Error,FALSE,12.7,8.42,3.14,Low,2.08,low,1
Computer Vision,Hand,Hand Pose Estimation,MSRA Hands,Dense Pixel-wise Estimation,Average 3D Error,FALSE,9.8,7.2,2.42,Low,1.78,low,1
Computer Vision,Hand,Hand Pose Estimation,ICVL Hands,V2V-PoseNet,Average 3D Error,FALSE,7.5,6.28,1.85,Low,1.55,low,1
Computer Vision,Hand,Hand Pose Estimation,HANDS 2017,V2V-PoseNet,Average 3D Error,FALSE,9.95,9.95,2.46,Low,2.46,low,1
Computer Vision,Crowds,Crowd Counting,UCF CC 50,Cascaded-MTL,MAE,FALSE,322.8,322.8,79.88,High,79.88,High,4
Computer Vision,Crowds,Crowd Counting,ShanghaiTech A,Cascaded-MTL,MAE,FALSE,101.3,101.3,25.06,High,25.06,High,4
Computer Vision,Crowds,Crowd Counting,ShanghaiTech B,Cascaded-MTL,MAE,FALSE,20,20,4.94,Low,4.94,low,1
Computer Vision,Facial Recognition and Modelling,3D Face Reconstruction,Florence,PRN,Mean NME ,FALSE,0.06,0.04,0.01,Low,0,low,1
Computer Vision,Facial Recognition and Modelling,3D Face Reconstruction,AFLW2000-3D,PRN,Mean NME ,FALSE,0.05,0.04,0.01,Low,0,low,1
Computer Vision,Facial Recognition and Modelling,Face Generation,CelebA,COCO-GAN,FID,FALSE,7.3,5.74,1.8,Low,1.42,low,1
Computer Vision,Gaze Estimation,Gaze Estimation,MPII Gaze,RT-GENE 4 model ensemble,Angular Error,FALSE,4.3,4.3,1.06,Low,1.06,low,1
Computer Vision,Gaze Estimation,Gaze Estimation,RT-GENE,RT-GENE 4 model ensemble,Angular Error,FALSE,7.7,7.7,1.9,Low,1.9,low,1
Computer Vision,Gaze Estimation,Gaze Estimation,UT Multi-view,RT-GENE 4 model ensemble,Angular Error,FALSE,5.1,5.1,1.26,Low,1.26,low,1
Computer Vision,Facial Recognition and Modelling,Facial Landmark Detection,300W,SAN GT,NME,FALSE,6.3,3.98,1.55,Low,0.98,low,1
Computer Vision,Facial Recognition and Modelling,Facial Landmark Detection,AFLW-Full,SAN,Mean NME ,FALSE,1.91,1.91,0.47,Low,0.47,low,1
Computer Vision,Facial Recognition and Modelling,Facial Landmark Detection,AFLW-Front,SAN,Mean NME ,FALSE,1.85,1.85,0.45,Low,0.45,low,1
Computer Vision,Object Localization,Weakly-Supervised Object Localization, CUB-200-2011,SPG,Top-1 Error Rate,FALSE,53.36,53.36,13.2,Low,13.2,High,2
Computer Vision,Object Localization,Weakly-Supervised Object Localization,ILSVRC 2015,SPG,Top-1 Error Rate,FALSE,51.4,51.4,12.72,Low,12.72,High,2
Computer Vision,Object Localization,Weakly-Supervised Object Localization,ILSVRC 2016,SPG,Top-5 Error,FALSE,40,40,9.89,Low,9.89,High,2
Computer Vision,Image Classification,Fine-Grained Image Classification,Caltech-101,AutoAugment,Top-1 Error Rate,FALSE,0.13,0.13,0.03,Low,0.03,low,1
Computer Vision,Image Classification,Fine-Grained Image Classification,Oxford-IIIT Pets,AutoAugment,Top-1 Error Rate,FALSE,0.11,0.11,0.02,Low,0.02,low,1
Computer Vision,Image Generation,Text-to-Image Generation,Oxford 102 Flowers,StackGAN-v2,FID,FALSE,48.68,48.68,12.04,Low,12.04,High,2
Computer Vision,Pose Estimation,Head Pose Estimation,BIWI,Multi-Loss ResNet50,MAE,FALSE,19.07,4.9,4.71,Low,1.21,low,1
Computer Vision,Pose Estimation,Head Pose Estimation,AFLW2000,Multi-Loss ResNet50,MAE,FALSE,7.39,6.16,1.82,Low,1.52,low,1
Computer Vision,Facial Recognition and Modelling,Age Estimation,FGNET,CMAAE-OR,MAE,FALSE,3.62,3.62,0.89,Low,0.89,low,1
Computer Vision,Facial Recognition and Modelling,Age Estimation,MORPH,CMAAE-OR,MAE,FALSE,1.48,1.48,0.36,Low,0.36,low,1
Computer Vision,Facial Recognition and Modelling,Age Estimation,ChaLearn 2015,DLDL+VGG-Face,MAE,FALSE,3.51,3.51,0.86,Low,0.86,low,1
Computer Vision,Dense Pixel Correspondence Estimation,Dense Pixel Correspondence Estimation,HPatches,DGC-Net aff+tps+homo,Viewpoint I AEPE,FALSE,5.84,1.55,1.44,Low,0.38,low,1
Computer Vision,Facial Recognition and Modelling,Face Anti-Spoofing,MSU-MFSD,GFA-CNN,Equal Error Rate,FALSE,0.11,0.08,0.02,Low,0.01,low,1
Computer Vision,Facial Recognition and Modelling,Facial Beauty Prediction,SCUT-FBP,CNN features + Bayesian ridge regression,MAE,FALSE,0.39,0.26,0.09,Low,0.06,low,1
Computer Vision,Instance Segmentation,One-Shot Instance Segmentation,COCO,Siamese Mask R-CNN,AP 0.5,FALSE,14.5,14.5,3.58,Low,3.58,low,1
,,,,,,,,,15.04597973,,9.163074324,,
