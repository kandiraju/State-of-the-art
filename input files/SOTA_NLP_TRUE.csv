Area,Parent Task,Task,Dataset,Best method name,Primary metric,Primary metric - is higher better?,Metric first reported value,2013,2014,2015,2016,2017,2018,2019
Natural Language Processing,Machine Translation,Machine Translation,WMT2014 English-French,Transformer Big + BT,BLEU score,TRUE,34.54,,37.50,37.50,39.92,41.40,45.60,45.60
Natural Language Processing,Machine Translation,Machine Translation,WMT2014 English-German,DeepL,BLEU score,TRUE,20.70,,,,26.30,28.90,29.30,29.70
Natural Language Processing,Machine Translation,Machine Translation,IWSLT2015 German-English,Transformer,BLEU score,TRUE,28.53,,28.53,28.53,30.40,34.44,34.44,34.44
Natural Language Processing,Machine Translation,Machine Translation,WMT2016 English-Romanian,ConvS2S BPE40k,BLEU score,TRUE,28.10,,,,28.90,29.88,29.88,29.88
Natural Language Processing,Machine Translation,Machine Translation,IWSLT2015 English-German,Transformer,BLEU score,TRUE,25.04,,,,25.04,28.23,28.23,28.23
Natural Language Processing,Machine Translation,Machine Translation,WMT2015 English-German,ByteNet,BLEU score,TRUE,22.80,,,22.80,26.26,26.26,26.26,26.26
Natural Language Processing,Machine Translation,Machine Translation,WMT2016 English-German,Attentional encoder-decoder + BPE,BLEU score,TRUE,34.20,,,,34.20,34.20,34.20,34.20
Natural Language Processing,Machine Translation,Machine Translation,WMT2016 German-English,Attentional encoder-decoder + BPE,BLEU score,TRUE,38.60,,,,38.60,38.60,38.60,38.60
Natural Language Processing,Machine Translation,Machine Translation,WMT2016 English-Russian,Attentional encoder-decoder + BPE,BLEU score,TRUE,26.00,,,,26.00,26.00,26.00,26.00
Natural Language Processing,Machine Translation,Machine Translation,WMT2016 Romanian-English,MLM pretraining,BLEU score,TRUE,33.30,,,,33.30,33.30,33.30,35.30
Natural Language Processing,Machine Translation,Machine Translation,WMT2014 German-English,Denoising autoencoders (non-autoregressive),BLEU score,TRUE,23.20,,,,,23.20,25.43,25.43
Natural Language Processing,Machine Translation,Machine Translation,WMT2016 English-Czech,Attentional encoder-decoder + BPE,BLEU score,TRUE,25.80,,,,25.80,25.80,25.80,25.80
Natural Language Processing,Machine Translation,Machine Translation,WMT 2014 EN-DE,universal transformer base,BLEU,TRUE,28.90,,,,,,28.90,28.90
Natural Language Processing,Machine Translation,Machine Translation,IWSLT2015 Thai-English,Seq-KD + Seq-Inter + Word-KD,BLEU score,TRUE,14.20,,,,14.20,14.20,14.20,14.20
Natural Language Processing,Machine Translation,Machine Translation,WMT2015 English-Russian,C2-50k Segmentation,BLEU score,TRUE,20.90,,,20.90,20.90,20.90,20.90,20.90
Natural Language Processing,Machine Translation,Machine Translation,WMT2016 Czech-English,Attentional encoder-decoder + BPE,BLEU score,TRUE,31.40,,,,31.40,31.40,31.40,31.40
Natural Language Processing,Machine Translation,Machine Translation,WMT2014 French-English,SMT + iterative backtranslation (unsupervised),BLEU score,TRUE,25.87,,,,,,25.87,25.87
Natural Language Processing,Machine Translation,Machine Translation,WMT2016 Russian-English,Attentional encoder-decoder + BPE,BLEU score,TRUE,28.00,,,,28.00,28.00,28.00,28.00
Natural Language Processing,Language Modelling,Language Modelling,Sequential MNIST,Trellis Network,Accuracy,TRUE,99.20,,,,,,99.20,99.20
Natural Language Processing,Question Answering,Question Answering,SQuAD1.1,BERT (ensemble),EM,TRUE,67.90,,,,75.03,82.28,87.43,87.43
Natural Language Processing,Question Answering,Question Answering,SQuAD2.0,BERT + DAE + AoA (ensemble),EM,TRUE,70.30,,,,,71.32,83.54,87.15
Natural Language Processing,Question Answering,Question Answering,CNN / Daily Mail,GA+MAGE (32),CNN,TRUE,69.40,,,69.40,77.90,78.60,78.60,78.60
Natural Language Processing,Question Answering,Question Answering,WikiQA,HyperQA,MAP,TRUE,0.60,,0.65,0.69,0.71,0.71,0.71,0.71
Natural Language Processing,Question Answering,Question Answering,bAbi,QRN,Accuracy (trained on 10k),TRUE,0.93,,,0.93,1.00,1.00,1.00,1.00
Natural Language Processing,Question Answering,Question Answering,Children's Book Test,GPT-2,Accuracy-CN,TRUE,0.69,,,,0.72,0.72,0.72,0.93
Natural Language Processing,Question Answering,Question Answering,CoQA,BERT Large Augmented (single model),In-domain,TRUE,67.00,,,,,,82.50,82.50
Natural Language Processing,Question Answering,Question Answering,QASent,Attentive LSTM,MAP,TRUE,0.68,,0.71,0.73,0.73,0.73,0.73,0.73
Natural Language Processing,Question Answering,Question Answering,NarrativeQA,ConZNet,Rouge-L,TRUE,36.74,,,,36.74,36.74,46.67,46.67
Natural Language Processing,Question Answering,Question Answering,SemEvalCQA,HyperQA,P@1,TRUE,0.75,,,0.75,0.76,0.81,0.81,0.81
Natural Language Processing,Question Answering,Question Answering,YahooCQA,HyperQA,P@1,TRUE,0.57,,,,0.57,0.68,0.68,0.68
Natural Language Processing,Question Answering,Question Answering,TriviaQA,MemoReader,EM,TRUE,46.94,,,,,66.37,67.21,67.21
Natural Language Processing,Question Answering,Question Answering,MS MARCO,Masque Q&A Style,Rouge-L,TRUE,23.96,,,,23.96,23.96,52.01,52.20
Natural Language Processing,Question Answering,Question Answering,NewsQA,DecaProp,F1,TRUE,56.10,,,,,56.10,66.30,66.30
Natural Language Processing,Question Answering,Question Answering,TrecQA,HyperQA,MAP,TRUE,0.71,,0.71,0.71,0.76,0.77,0.77,0.77
Natural Language Processing,Question Answering,Question Answering,WikiHop,CFC,Test,TRUE,42.90,,,,,42.90,59.30,70.60
Natural Language Processing,Question Answering,Question Answering,Story Cloze Test,Finetuned Transformer LM,Accuracy,TRUE,78.70,,,,78.70,78.70,78.70,78.70
Natural Language Processing,Question Answering,Question Answering,WebQuestions,Memory Networks (ensemble),F1,TRUE,0.30,,0.39,0.42,0.42,0.42,0.42,0.42
Natural Language Processing,Question Answering,Question Answering,CliCR,Gated-Attention Reader,F1,TRUE,33.90,,,,,,33.90,33.90
Natural Language Processing,Question Answering,Question Answering,RACE,Finetuned Transformer LM,RACE-m,TRUE,60.20,,,,,,60.20,60.20
Natural Language Processing,Question Answering,Question Answering,Reverb,Weakly Supervised Embeddings,Accuracy,TRUE,0.73,,0.73,0.73,0.73,0.73,0.73,0.73
Natural Language Processing,Question Answering,Question Answering,MCTest-500,Parallel-Hierarchical,Accuracy,TRUE,0.71,,,,0.71,0.71,0.71,0.71
Natural Language Processing,Question Answering,Question Answering,Quora Question Pairs,BERT (single model),Accuracy,TRUE,0.72,,,,,,0.72,0.72
Natural Language Processing,Question Answering,Question Answering,QuAC,FlowQA (single model),F1,TRUE,64.10,,,,,,64.10,64.10
Natural Language Processing,Question Answering,Question Answering,Natural Questions,BERT-joint,F1 (Long),TRUE,66.20,,,,,,,66.20
Natural Language Processing,Question Answering,Question Answering,SimpleQuestions,Memory Networks (ensemble),F1,TRUE,0.64,,,0.64,0.64,0.64,0.64,0.64
Natural Language Processing,Question Answering,Question Answering,MCTest-160,"syntax, frame, coreference, and word embedding features",Accuracy,TRUE,0.75,,,,0.75,0.75,0.75,0.75
Natural Language Processing,Sentiment Analysis,Sentiment Analysis,SST-2 Binary classification,MT-DNN,Accuracy,TRUE,85.40,85.40,85.40,87.80,89.70,93.20,93.20,95.60
Natural Language Processing,Sentiment Analysis,Sentiment Analysis,SST-5 Fine-grained classification,EDD-LG (shared),Accuracy,TRUE,45.70,45.70,49.60,49.60,49.60,53.70,64.40,64.40
Natural Language Processing,Sentiment Analysis,Sentiment Analysis,IMDb,ULMFiT,Accuracy,TRUE,92.33,,92.33,92.33,94.10,94.99,95.40,95.40
Natural Language Processing,Sentiment Analysis,Sentiment Analysis,MR,MEAN,Accuracy,TRUE,78.26,,,,,78.26,84.50,84.50
Natural Language Processing,Sentiment Analysis,Sentiment Analysis,Amazon Review Full,DRNN,Accuracy,TRUE,60.20,,,,60.20,60.20,64.43,64.43
Natural Language Processing,Sentiment Analysis,Sentiment Analysis,Amazon Review Polarity,DRNN,Accuracy,TRUE,94.60,,,,94.60,94.60,96.49,96.49
Natural Language Processing,Sentiment Analysis,Sentiment Analysis,Multi-Domain Sentiment Dataset,Distributional Correspondence Indexing,DVD,TRUE,75.40,,,76.57,76.57,76.57,81.00,81.00
Natural Language Processing,Sentiment Analysis,Sentiment Analysis,CR,Block-sparse LSTM,Accuracy,TRUE,92.20,,,,,92.20,92.20,92.20
Natural Language Processing,Sentiment Analysis,Sentiment Analysis,SemEval,LSTMs+CNNs ensemble with multiple conv. ops ,F1-score,TRUE,0.69,,,,,0.69,0.69,0.69
Natural Language Processing,Sentiment Analysis,Sentiment Analysis,MPQA,USE_T+DAN (w2v w.e.) ,Accuracy,TRUE,88.14,,,,,,88.14,88.14
Natural Language Processing,Sentiment Analysis,Sentiment Analysis,Sogou News,fastText,Accuracy,TRUE,96.80,,,,96.80,96.80,96.80,96.80
Natural Language Processing,Text Classification,Text Classification,Yahoo! Answers,DRNN,Accuracy,TRUE,72.30,,,,72.30,72.30,76.26,76.26
Natural Language Processing,Text Classification,Text Classification,Ohsumed,SGCN,Accuracy,TRUE,36.20,,,,,36.20,68.36,68.50
Natural Language Processing,Text Classification,Text Classification,R52,SGCN,Accuracy,TRUE,93.56,,,,,,93.56,94.00
Natural Language Processing,Text Classification,Text Classification,20NEWS,SGCN,Accuracy,TRUE,86.34,,,,,,86.34,88.50
Natural Language Processing,Text Classification,Text Classification,R8,SGCN,Accuracy,TRUE,97.07,,,,,,97.07,97.20
Natural Language Processing,Text Classification,Text Classification,Sogou News,CCCapsNet,Accuracy,TRUE,97.25,,,,,,97.25,97.25
Natural Language Processing,Text Classification,Text Classification,IMDb,L MIXED,Accuracy,TRUE,95.68,,,,,,,95.68
Natural Language Processing,Natural Language Inference,Natural Language Inference,SNLI,MT-DNN,% Test Accuracy,TRUE,78.20,,,86.10,88.60,89.30,90.10,91.10
Natural Language Processing,Natural Language Inference,Natural Language Inference,MultiNLI,MT-DNN,Matched,TRUE,71.40,,,,,,73.90,86.70
Natural Language Processing,Natural Language Inference,Natural Language Inference,SciTail,MT-DNN,Accuracy,TRUE,83.30,,,,,83.30,92.00,94.10
Natural Language Processing,Natural Language Inference,Natural Language Inference,V-SNLI,V-BiMPM,Accuracy,TRUE,86.99,,,,,,86.99,86.99
Natural Language Processing,Natural Language Inference,Natural Language Inference,Quora Question Pairs,aESIM,Accuracy,TRUE,88.01,,,,,,88.01,88.01
Natural Language Processing,Named Entity Recognition (NER),Named Entity Recognition (NER),CoNLL 2003 (English),CNN Large + fine-tune,F1,TRUE,91.21,,,,91.21,91.93,93.09,93.50
Natural Language Processing,Named Entity Recognition (NER),Named Entity Recognition (NER),Ontonotes v5 (English),Flair embeddings,F1,TRUE,86.99,,,,,86.99,89.71,89.71
Natural Language Processing,Named Entity Recognition (NER),Named Entity Recognition (NER),JNLPBA,CollaboNet,F1,TRUE,78.58,,,,,,78.58,78.58
Natural Language Processing,Named Entity Recognition (NER),Named Entity Recognition (NER),BC5CDR,SciBERT (SciVocab),F1,TRUE,87.12,,,,,,87.12,88.94
Natural Language Processing,Named Entity Recognition (NER),Named Entity Recognition (NER),Long-tail emerging entities,Flair embeddings,F1,TRUE,40.78,,,,,40.78,50.20,50.20
Natural Language Processing,Named Entity Recognition (NER),Named Entity Recognition (NER),SciERC,SciBERT (SciVocab),F1,TRUE,64.20,,,,,,64.20,65.50
Natural Language Processing,Named Entity Recognition (NER),Named Entity Recognition (NER),NCBI-disease,SciBERT (Base Vocab),F1,TRUE,86.91,,,,,,,86.91
Natural Language Processing,Text Generation,Text Generation,EMNLP2017 WMT,LeakGAN,BLEU-2,TRUE,0.86,,,,0.86,0.96,0.96,0.96
Natural Language Processing,Text Generation,Text Generation,COCO Captions,LeakGAN,BLEU-2,TRUE,0.83,,,,0.83,0.95,0.95,0.95
Natural Language Processing,Text Generation,Text Generation,Chinese Poems,LeakGAN,BLEU-2,TRUE,0.74,,,,0.74,0.88,0.88,0.88
Natural Language Processing,Text Generation,Text Generation,CMU-SE,STWGAN-GP,BLEU-3,TRUE,0.62,,,,,,0.62,0.62
Natural Language Processing,Text Generation,Text Generation,DailyDialog,AEM+Attention,BLEU-1,TRUE,14.17,,,,,,14.17,14.17
Natural Language Processing,Text Generation,Text Generation,LDC2016E25,Graph2Seq,BLEU,TRUE,22.00,,,,,,22.00,22.00
Natural Language Processing,Dependency Parsing,Dependency Parsing,Penn Treebank,CVT + Multi-Task,UAS,TRUE,93.99,,,93.99,95.44,95.44,96.61,96.61
Natural Language Processing,Dependency Parsing,Dependency Parsing,GENIA - LAS,BiLSTM-CRF,F1,TRUE,91.92,,,,,,91.92,91.92
Natural Language Processing,Dependency Parsing,Dependency Parsing,GENIA - UAS,BiLSTM-CRF,F1,TRUE,92.84,,,,,,92.84,92.84
Natural Language Processing,Relation Extraction,Relation Extraction,TACRED,TRE,F1,TRUE,65.10,,,,,65.10,66.40,67.40
Natural Language Processing,Relation Extraction,Relation Extraction,ChemProt,SciBERT (SciVocab),F1,TRUE,76.12,,,,,,,76.12
Natural Language Processing,Relation Extraction,Relation Extraction,SciERC,SciBERT (SciVocab),F1,TRUE,74.64,,,,,,,74.64
Natural Language Processing,Semantic Textual Similarity,Semantic Textual Similarity,SentEval,GenSen,MRPC,TRUE,0.91,,,,,0.91,0.93,0.93
Natural Language Processing,Semantic Textual Similarity,Semantic Textual Similarity,STS Benchmark,USE_T,Pearson Correlation,TRUE,0.78,,,,,,0.78,0.78
Natural Language Processing,Part-Of-Speech Tagging,Part-Of-Speech Tagging,Penn Treebank,Meta BiLSTM,Accuracy,TRUE,97.78,,,97.78,97.78,97.78,97.96,97.96
Natural Language Processing,Part-Of-Speech Tagging,Part-Of-Speech Tagging,UD,Adversarial Bi-LSTM,Avg accuracy,TRUE,96.40,,,,96.40,96.73,96.73,96.73
Natural Language Processing,Part-Of-Speech Tagging,Part-Of-Speech Tagging,Social media,GATE,Accuracy,TRUE,,,,,,,,
Natural Language Processing,Semantic Parsing,Semantic Parsing,spider,Exact Set Matching,Accuracy,TRUE,19.70,,,,,,19.70,19.70
Natural Language Processing,Text Classification,Document Classification,WOS-11967,RMDL,Accuracy,TRUE,86.07,,,,,86.07,91.59,91.59
Natural Language Processing,Text Classification,Document Classification,WOS-46985,RMDL,Accuracy,TRUE,76.58,,,,,76.58,90.69,90.69
Natural Language Processing,Text Classification,Document Classification,WOS-5736,RMDL,Accuracy,TRUE,90.93,,,,,90.93,93.57,93.57
Natural Language Processing,Text Classification,Document Classification,Reuters-21578,RMDL,Accuracy,TRUE,90.69,,,,,,90.69,90.69
Natural Language Processing,Text Classification,Document Classification,IMDb,RMDL,Accuracy,TRUE,90.79,,,,,,90.79,90.79
Natural Language Processing,Text Classification,Document Classification,20NEWS,RMDL,Accuracy,TRUE,87.91,,,,,,87.91,87.91
Natural Language Processing,Semantic Role Labeling,Semantic Role Labeling,OntoNotes,BiLSTM-Span (Ensemble),F1,TRUE,81.70,,,,,82.70,87.00,87.00
Natural Language Processing,Semantic Role Labeling,Semantic Role Labeling,CoNLL 2005,BiLSTM-Span (Ensemble),F1,TRUE,86.04,,,,,,88.50,88.50
Natural Language Processing,Coreference Resolution,Coreference Resolution,CoNLL 2012,"(Lee et al., 2017)+ELMo",Avg F1,TRUE,67.20,,,,,67.20,73.00,73.00
Natural Language Processing,Text Summarization,Text Summarization,GigaWord,FTSum_g,ROUGE-1,TRUE,36.40,,,,36.40,37.27,37.27,37.27
Natural Language Processing,Text Summarization,Text Summarization,DUC 2004 Task 1,EndDec+WFE,ROUGE-1,TRUE,28.61,,,,28.97,32.28,32.28,32.28
Natural Language Processing,Word Sense Disambiguation,Word Sense Disambiguation,SensEval 2,"SemCor+WNGT, vocabulary reduced, ensemble",F1,TRUE,74.40,,,,74.40,74.40,75.15,75.15
Natural Language Processing,Word Sense Disambiguation,Word Sense Disambiguation,SemEval 2013 Task 12,"SemCor+WNGT, vocabulary reduced, ensemble",F1,TRUE,69.50,,,,69.50,69.50,72.63,72.63
Natural Language Processing,Word Sense Disambiguation,Word Sense Disambiguation,SensEval 3 Task 1,"LSTMLP (T:SemCor, U:1K)",F1,TRUE,71.80,,,,71.80,71.80,71.80,71.80
Natural Language Processing,Word Sense Disambiguation,Word Sense Disambiguation,SemEval 2007 Task 7,"SemCor+WNGT, vocabulary reduced, ensemble",F1,TRUE,84.30,,,,84.30,84.30,86.02,86.02
Natural Language Processing,Word Sense Disambiguation,Word Sense Disambiguation,SemEval 2007 Task 17,"SemCor+WNGT, vocabulary reduced, ensemble",F1,TRUE,64.20,,,,64.20,64.20,66.81,66.81
Natural Language Processing,Word Sense Disambiguation,Word Sense Disambiguation,Knowledge-based:,WSD-TM,All,TRUE,66.90,,,,,,66.90,66.90
Natural Language Processing,Word Sense Disambiguation,Word Sense Disambiguation,SemEval 2015 Task 13,"SemCor+WNGT, vocabulary reduced, ensemble",F1,TRUE,72.60,,,,,,74.46,74.46
Natural Language Processing,Entity Linking,Entity Linking,WebQSP-WD,VCG,F1,TRUE,0.73,,,,,,0.73,0.73
Natural Language Processing,Text Summarization,Document Summarization,CNN / Daily Mail,BERTSUM+Transformer,ROUGE-1,TRUE,31.10,,,,,31.10,41.22,43.25
Natural Language Processing,Relation Classification,Relation Classification,SemEval-2010 Task 8,TRE,F1,TRUE,87.10,,,,,,,87.10
Natural Language Processing,Text Classification,Sentence Classification,SciCite,SciBERT,F1,TRUE,77.20,,,,,77.20,82.60,84.90
Natural Language Processing,Text Classification,Sentence Classification,ACL-ARC,Structural-scaffolds,F1,TRUE,53.00,,,,,,53.00,67.90
Natural Language Processing,Text Classification,Sentence Classification,PubMed 20k RCT,Hierarchical Neural Networks,F1,TRUE,92.60,,,,,,92.60,92.60
Natural Language Processing,Text Classification,Sentence Classification,Paper Field,SciBERT (SciVocab),F1,TRUE,64.07,,,,,,,64.07
Natural Language Processing,Text Classification,Sentence Classification,ScienceCite,SciBERT (SciVocab),F1,TRUE,84.99,,,,,,,84.99
Natural Language Processing,Dialogue,Dialogue Generation,Ubuntu Dialogue (Activity),MrRNN Act.-Ent.,F1,TRUE,11.43,,,,11.43,11.43,11.43,11.43
Natural Language Processing,Dialogue,Dialogue Generation,Ubuntu Dialogue (Entity),MrRNN Act.-Ent.,F1,TRUE,3.72,,,,3.72,3.72,3.72,3.72
Natural Language Processing,Dialogue,Dialogue Generation,Ubuntu Dialogue (Tense),MrRNN Act.-Ent.,Accuracy,TRUE,0.29,,,,0.29,0.29,0.29,0.29
Natural Language Processing,Dialogue,Dialogue Generation,Ubuntu Dialogue (Cmd),MrRNN Act.-Ent.,Accuracy,TRUE,0.95,,,,0.95,0.95,0.95,0.95
Natural Language Processing,Dialogue,Dialogue Generation,Twitter Dialogue (Noun),MrRNN Act.-Ent.,F1,TRUE,4.63,,,,4.63,4.63,4.63,4.63
Natural Language Processing,Dialogue,Dialogue Generation,Twitter Dialogue (Tense),MrRNN Act.-Ent.,Accuracy,TRUE,0.34,,,,0.34,0.34,0.34,0.34
Natural Language Processing,Chunking,Chunking,Penn Treebank,Flair embeddings,F1 score,TRUE,95.57,,,,95.77,95.77,96.72,96.72
Natural Language Processing,Paraphrase Identification,Paraphrase Identification,Quora Question Pairs,MT-DNN,Accuracy,TRUE,88.17,,,,,89.06,89.06,89.60
Natural Language Processing,Sentiment Analysis,Aspect-Based Sentiment Analysis,SemEval 2014 Task 4 Sub Task 2,HAPN,Restaurant (Acc),TRUE,75.63,,,75.63,80.95,80.95,82.23,82.23
Natural Language Processing,Sentiment Analysis,Aspect-Based Sentiment Analysis,Sentihood,Liu et al.,Aspect,TRUE,69.30,,,,69.30,69.30,78.50,78.50
Natural Language Processing,Constituency Parsing,Constituency Parsing,Penn Treebank,CNN Large + fine-tune,F1 score,TRUE,92.10,,92.10,92.10,93.80,94.66,95.13,95.60
Natural Language Processing,Language Acquisition,Language Acquisition,SLAM 2018,Context Based Model,AUC,TRUE,0.82,,,,,,0.82,0.82
Natural Language Processing,Ad-Hoc Information Retrieval,Ad-Hoc Information Retrieval,TREC Robust04,Anserini BM25+RM3,MAP,TRUE,0.28,,,,,0.28,0.30,0.30
Natural Language Processing,Chinese,Chinese Word Segmentation,MSRA,Pre-trained+bigram+ LSTM+CRF,F1,TRUE,97.40,,,97.40,97.40,97.40,97.40,97.40
Natural Language Processing,Grammatical Error Correction,Grammatical Error Correction,Restricted,SMT + BiGRU,F0.5,TRUE,54.79,,,,,,72.04,72.04
Natural Language Processing,Grammatical Error Correction,Grammatical Error Correction,Unrestricted,CNN Seq2Seq + Fluency Boost,F0.5,TRUE,76.88,,,,,,76.88,76.88
Natural Language Processing,Grammatical Error Correction,Grammatical Error Correction,_Restricted_,SMT + BiGRU,GLEU,TRUE,57.47,,,,,,61.50,61.50
Natural Language Processing,Question Answering,Open-Domain Question Answering,SearchQA,DecaProp,N-gram F1,TRUE,22.80,,,,22.80,22.80,70.80,70.80
Natural Language Processing,Question Answering,Open-Domain Question Answering,Quasar,Denoising QA,EM (Quasar-T),TRUE,26.40,,,,26.40,26.40,42.20,42.20
Natural Language Processing,Dialogue,Dialogue State Tracking,Second dialogue state tracking challenge,StateNet,Joint,TRUE,73.40,,,,73.40,73.40,75.50,75.50
Natural Language Processing,Dialogue,Dialogue State Tracking,Wizard-of-Oz,StateNet,Joint,TRUE,84.40,,,,84.40,84.40,88.90,88.90
Natural Language Processing,Text Classification,Emotion Classification,SemEval 2018 Task 1E-c,Transformer (finetune),Macro-F1,TRUE,56.10,,,,,,56.10,56.10
Natural Language Processing,Sentiment Analysis,Multimodal Sentiment Analysis,MOSI,MMMU-BA,Accuracy,TRUE,0.80,,,,,0.80,0.82,0.82
Natural Language Processing,Amr Parsing,Amr Parsing,LDC2014T12:,Transition-based+improved aligner+ensemble,F1 Newswire,TRUE,0.70,,,,0.71,0.71,0.73,0.73
Natural Language Processing,Subjectivity Analysis,Subjectivity Analysis,SUBJ,AdaSent,Accuracy,TRUE,95.50,,,95.50,95.50,95.50,95.50,95.50
Natural Language Processing,Text Generation,Data-to-Text Generation,E2E NLG Challenge,S_1^R,BLEU,TRUE,64.22,,,,,64.22,66.19,68.60
Natural Language Processing,Text Generation,Data-to-Text Generation,Rotowire (Content Selection),Neural Content Planning + conditional copy,Precision,TRUE,0.29,,,,,0.29,0.34,0.34
Natural Language Processing,Text Generation,Data-to-Text Generation,RotoWire (Content Ordering),Neural Content Planning + conditional copy,DLD,TRUE,0.15,,,,,0.15,0.19,0.19
Natural Language Processing,Text Generation,Data-to-Text Generation,RotoWire (Relation Generation),Neural Content Planning + conditional copy,Precision,TRUE,0.75,,,,,0.75,0.87,0.87
Natural Language Processing,Text Generation,Data-to-Text Generation,RotoWire,Neural Content Planning + conditional copy,BLEU,TRUE,14.19,,,,,14.19,16.50,16.50
Natural Language Processing,Text Generation,Data-to-Text Generation,SR11Deep,GCN + feat,BLEU,TRUE,0.67,,,,,,0.67,0.67
Natural Language Processing,Text Generation,Data-to-Text Generation,WebNLG,GCN EC,BLEU,TRUE,0.56,,,,,,0.56,0.56
Natural Language Processing,Sarcasm Detection,Sarcasm Detection,SARC (all-bal),CASCADE,Accuracy,TRUE,75.80,,,,,75.80,77.00,77.00
Natural Language Processing,Sarcasm Detection,Sarcasm Detection,SARC (pol-bal),Bag-of-Bigrams,Accuracy,TRUE,76.50,,,,,76.50,76.50,76.50
Natural Language Processing,Sarcasm Detection,Sarcasm Detection,SARC (pol-unbal),Bag-of-Words,Avg F1,TRUE,27.00,,,,,27.00,27.00,27.00
Natural Language Processing,Stance Detection,Stance Detection,RumourEval,Kochkina et al. 2017,Accuracy,TRUE,0.78,,,,,0.78,0.78,0.78
Natural Language Processing,Sentence Embeddings,Sentence Compression,Google Dataset,BiLSTM,CR,TRUE,0.43,,,,,0.43,0.43,0.43
Natural Language Processing,Machine Translation,Unsupervised Machine Translation,WMT2014 French-English,SMT + NMT (tuning and joint refinement),BLEU,TRUE,27.70,,,,,,27.70,33.50
Natural Language Processing,Machine Translation,Unsupervised Machine Translation,WMT2016 English-German,SMT + NMT (tuning and joint refinement),BLEU,TRUE,20.20,,,,,,20.20,26.90
Natural Language Processing,Machine Translation,Unsupervised Machine Translation,WMT2016 German-English,SMT + NMT (tuning and joint refinement),BLEU,TRUE,25.20,,,,,,26.70,34.40
Natural Language Processing,Machine Translation,Unsupervised Machine Translation,WMT2014 English-French,SMT + NMT (tuning and joint refinement),BLEU,TRUE,27.60,,,,,,27.60,36.20
Natural Language Processing,Machine Translation,Unsupervised Machine Translation,WMT2014 German-English,SMT + NMT (tuning and joint refinement),BLEU,TRUE,20.40,,,,,,,27.00
Natural Language Processing,Machine Translation,Unsupervised Machine Translation,WMT2014 English-German,SMT + NMT (tuning and joint refinement),BLEU,TRUE,17.00,,,,,,,22.50
Natural Language Processing,Machine Translation,Unsupervised Machine Translation,WMT2016 Romanian-English,MLM pretraining for encoder and decoder,BLEU,TRUE,31.80,,,,,,,31.80
Natural Language Processing,Information Extraction,Temporal Information Extraction,TimeBank,Catena,F1 score,TRUE,0.51,,,,0.51,0.51,0.51,0.51
Natural Language Processing,Information Extraction,Temporal Information Extraction,TempEval-3,Ning et al.,Temporal awareness,TRUE,67.20,,,,,67.20,67.20,67.20
Natural Language Processing,Graph-to-Sequence,Graph-to-Sequence,LDC2015E86:,GCNSEQ,BLEU,TRUE,23.95,,,,,,,23.95
Natural Language Processing,Cross-Lingual,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-Spanish,Massively Multilingual Sentence Embeddings,Accuracy,TRUE,0.73,,,,,,0.77,0.77
Natural Language Processing,Cross-Lingual,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-French,Massively Multilingual Sentence Embeddings,Accuracy,TRUE,0.75,,,,,,0.78,0.78
Natural Language Processing,Cross-Lingual,Cross-Lingual Document Classification,MLDoc Zero-Shot English-to-German,Massively Multilingual Sentence Embeddings,Accuracy,TRUE,0.81,,,,,,0.85,0.85
Natural Language Processing,Text Summarization,Extractive Document Summarization,CNN / Daily Mail,BERTSUM,ROUGE-2,TRUE,20.24,,,,,,,20.24
Natural Language Processing,Grammatical Error Correction,Grammatical Error Detection,CoNLL-2014 A1,Bi-LSTM + POS (unrestricted data),F0.5,TRUE,34.30,,,,34.30,36.10,36.10,36.10
Natural Language Processing,Grammatical Error Correction,Grammatical Error Detection,CoNLL-2014 A2,Bi-LSTM + POS (unrestricted data),F0.5,TRUE,44.00,,,,44.00,45.10,45.10,45.10
Natural Language Processing,Grammatical Error Correction,Grammatical Error Detection,FCE,BiLSTM-JOINT,F0.5,TRUE,41.10,,,,41.88,49.11,52.07,52.07
Natural Language Processing,Grammatical Error Correction,Grammatical Error Detection,JFLEG,BiLSTM-JOINT (trained on FCE),F0.5,TRUE,52.52,,,,,,52.52,52.52
Natural Language Processing,Natural Language Inference,Cross-Lingual Natural Language Inference,XNLI Zero-Shot English-to-Spanish,BERT,Accuracy,TRUE,0.69,,,,,0.69,0.74,0.74
Natural Language Processing,Natural Language Inference,Cross-Lingual Natural Language Inference,XNLI Zero-Shot English-to-German,BiLSTM,Accuracy,TRUE,0.68,,,,,0.68,0.73,0.73
Natural Language Processing,Natural Language Inference,Cross-Lingual Natural Language Inference,XNLI Zero-Shot English-to-French,BiLSTM,Accuracy,TRUE,0.68,,,,,0.68,0.72,0.72
Natural Language Processing,Text Classification,Citation Intent Classification,ACL-ARC,Structural-scaffolds,F1,TRUE,41.00,41.00,41.00,41.00,51.80,51.80,54.60,67.90
Natural Language Processing,Text Classification,Citation Intent Classification,SciCite,SciBERT,F1,TRUE,79.60,,,,,,82.60,84.99
Natural Language Processing,Question Answering,Knowledge Base Question Answering,WebQSP-WD,GGNN,Avg F1,TRUE,0.26,,,,,,0.26,0.26
Natural Language Processing,Relationship Extraction (Distant Supervised),Relationship Extraction (Distant Supervised),New York Times Corpus,RESIDE,P@10%,TRUE,69.40,,,,69.40,69.40,73.60,73.60
Natural Language Processing,CCG Supertagging,CCG Supertagging,CCGBank,Clark et al.,Accuracy,TRUE,94.70,,,,94.70,94.70,96.10,96.10
Natural Language Processing,Text Generation,Table-to-text Generation,WikiBio,Field-gating Seq2seq + dual attention,BLEU,TRUE,34.70,,,,34.70,44.89,44.89,44.89
Natural Language Processing,Passage Re-Ranking,Passage Re-Ranking,MS MARCO,BERT + Small Training,MRR,TRUE,0.36,,,,,,,0.36
Natural Language Processing,Named Entity Recognition (NER),Chinese Named Entity Recognition,Weibo NER,Lattice,F1,TRUE,58.79,,,,,,58.79,58.79
Natural Language Processing,Named Entity Recognition (NER),Chinese Named Entity Recognition,MSRA,Lattice,F1,TRUE,93.18,,,,,,93.18,93.18
Natural Language Processing,Named Entity Recognition (NER),Chinese Named Entity Recognition,OntoNotes 4,Lattice,F1,TRUE,73.88,,,,,,73.88,73.88
Natural Language Processing,Named Entity Recognition (NER),Chinese Named Entity Recognition,Resume NER,Lattice,F1,TRUE,94.46,,,,,,94.46,94.46
Natural Language Processing,Named Entity Recognition (NER),Chinese Named Entity Recognition,SighanNER,BiLSTM+CRF+adversarial+self-attention,F1,TRUE,90.64,,,,,,90.64,90.64
Natural Language Processing,Emotion Recognition,Emotion Recognition in Conversation,IEMOCAP,DialogueRNN,F1,TRUE,0.56,,,,,,0.65,0.65
Natural Language Processing,Hypernym Discovery,Hypernym Discovery,General,CRIM,MAP,TRUE,10.60,,,,10.60,10.60,19.78,19.78
Natural Language Processing,Hypernym Discovery,Hypernym Discovery,Medical domain,CRIM,MAP,TRUE,18.84,,,,18.84,18.84,34.05,34.05
Natural Language Processing,Hypernym Discovery,Hypernym Discovery,Music domain,CRIM,MAP,TRUE,12.99,,,,12.99,12.99,40.97,40.97
Natural Language Processing,Cross-Lingual Bitext Mining,Cross-Lingual Bitext Mining,BUCC German-to-English,Massively Multilingual Sentence Embeddings,F1 score,TRUE,76.90,,,76.90,76.90,76.90,96.19,96.19
Natural Language Processing,Cross-Lingual Bitext Mining,Cross-Lingual Bitext Mining,BUCC French-to-English,Massively Multilingual Sentence Embeddings,F1 score,TRUE,75.80,,,75.80,75.80,75.80,93.91,93.91
Natural Language Processing,Semantic Role Labeling,Predicate Detection,CoNLL 2005,LISA,F1,TRUE,96.40,,,,,96.40,98.40,98.40
Natural Language Processing,Semantic Role Labeling,Predicate Detection,CoNLL 2012,LISA,F1,TRUE,97.20,,,,,,97.20,97.20
Natural Language Processing,Dialogue,Dialogue Act Classification,Switchboard corpus,CRF-ASN,Accuracy,TRUE,79.20,,,,,81.30,81.30,81.30
Natural Language Processing,Dialogue,Dialogue Act Classification,ICSI Meeting Recorder Dialog Act (MRDA) corpus,CRF-ASN,Accuracy,TRUE,90.90,,,,,91.70,91.70,91.70
Natural Language Processing,Entity Resolution,Entity Resolution,CoNLL 2003 (English),deep joint entity disambiguation w/ neural attention,Accuracy,TRUE,92.22,,,,,92.22,92.22,92.22
Natural Language Processing,Semantic Role Labeling,Semantic Role Labeling (predicted predicates),CoNLL 2005,LISA + ELMo,F1,TRUE,86.90,,,,,,86.90,86.90
Natural Language Processing,Semantic Role Labeling,Semantic Role Labeling (predicted predicates),CoNLL 2012,LISA + ELMo,F1,TRUE,83.38,,,,,,83.38,83.38
Natural Language Processing,Anaphora Resolution,Abstract Anaphora Resolution,The ARRAU Corpus,MR-LSTM,Average Precision,TRUE,43.83,,,,,43.83,43.83,43.83
Natural Language Processing,Query Wellformedness,Query Wellformedness,Query Wellformedness,"word-1, 2 POS-1, 2, 3",Accuracy,TRUE,70.70,,,,,,70.70,70.70
Natural Language Processing,Lexical Normalization,Lexical Normalization,LexNorm,MoNoise,Accuracy,TRUE,87.63,,,,,87.63,87.63,87.63
